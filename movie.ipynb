{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(directory, label):\n",
    "    data = []\n",
    "    for filename in os.listdir(directory):\n",
    "        with open(os.path.join(directory, filename), 'r') as file:\n",
    "            review = file.read()\n",
    "            data.append((review, label))\n",
    "    return data\n",
    "\n",
    "directory_path = \"/Users/mrbinit/Downloads/aclImdb\" \n",
    "\n",
    "train_pos_dir = os.path.join(directory_path, 'train/pos')\n",
    "train_neg_dir = os.path.join(directory_path, 'train/neg')\n",
    "test_pos_dir = os.path.join(directory_path, 'test/pos')\n",
    "test_neg_dir = os.path.join(directory_path, 'test/neg')\n",
    "val_pos_dir = os.path.join(directory_path, 'val/pos')\n",
    "val_neg_dir = os.path.join(directory_path, 'val/neg')\n",
    "\n",
    "train_data = load_dataset(train_pos_dir, 1) + load_dataset(train_neg_dir, 0) #1 represents positive and 0 represents neghative sentiments\n",
    "test_data = load_dataset(test_pos_dir, 1) + load_dataset(test_neg_dir, 0)\n",
    "val_data = load_dataset(val_pos_dir, 1) + load_dataset(val_neg_dir, 0)\n",
    "\n",
    "# separate the reviews and labels from the train, test and validation data\n",
    "train_reviews, train_labels = zip(*train_data)\n",
    "test_reviews, test_labels = zip(*test_data)\n",
    "val_reviews, val_labels = zip(*val_data)\n",
    "\n",
    "# # convert lists to tensors\n",
    "# train_reviews = tf.convert_to_tensor(train_reviews) # tensor are used to represent multi dimensional arrays which are important for GPU computation\n",
    "# train_labels = tf.convert_to_tensor(train_labels)\n",
    "# test_reviews = tf.convert_to_tensor(test_reviews)\n",
    "# test_labels = tf.convert_to_tensor(test_labels)\n",
    "# val_reviews = tf.convert_to_tensor(val_reviews)\n",
    "# val_labels = tf.convert_to_tensor(val_labels)\n",
    "\n",
    "# # Create datasets from tensor\n",
    "# train_dataset = tf.data.Dataset.from_tensor_slices((train_reviews, train_labels)).batch(32)\n",
    "# test_dataset = tf.data.Dataset.from_tensor_slices((test_reviews, test_labels)).batch(32)\n",
    "# val_dataset = tf.data.Dataset.from_tensor_slices((val_reviews, val_labels)).batch(32)\n",
    "\n",
    "# # Shuffle the training dataset\n",
    "# train_dataset = train_dataset.shuffle(len(train_data))\n",
    "# test_dataset = test_dataset.shuffle(len(test_data))\n",
    "# val_dataset = val_dataset.shuffle(len(val_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#91% accuracy wiht over fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset contains HTML tags: True\n",
      "Test dataset contains HTML tags: True\n",
      "Validation dataset contains HTML tags: True\n"
     ]
    }
   ],
   "source": [
    "#Regular expressions (regex) are sequences of characters that define a search pattern. They are used for string manipulation, searching, and pattern matching within text. \n",
    "import re\n",
    "def has_html_tags(text):\n",
    "    pattern = re.compile(r'<[^>]+>')  # Regular expression to match HTML tags\n",
    "    return bool(pattern.search(text))\n",
    "\n",
    "# Check for HTML tags in each dataset\n",
    "def check_html_tags(dataset):\n",
    "    for review, _ in dataset:\n",
    "        if has_html_tags(review):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Check for HTML tags in each dataset\n",
    "train_has_html = check_html_tags(train_data)\n",
    "test_has_html = check_html_tags(test_data)\n",
    "val_has_html = check_html_tags(val_data)\n",
    "#ptinr output\n",
    "print(\"Train dataset contains HTML tags:\", train_has_html)\n",
    "print(\"Test dataset contains HTML tags:\", test_has_html)\n",
    "print(\"Validation dataset contains HTML tags:\", val_has_html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset contains URLs: True\n",
      "Test dataset contains URLs: True\n",
      "Validation dataset contains URLs: True\n"
     ]
    }
   ],
   "source": [
    "def has_url(text):\n",
    "    pattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    return bool(pattern.search(text))\n",
    "\n",
    "#condition to check for url\n",
    "def check_for_urls(dataset):\n",
    "    for review, _ in dataset:\n",
    "        if has_url(review):\n",
    "            return True\n",
    "    return False\n",
    "#check whether there is URL or not\n",
    "train_has_url = check_for_urls(train_data)\n",
    "test_has_url = check_for_urls(test_data)\n",
    "val_has_url = check_for_urls(val_data)\n",
    "\n",
    "print(\"Train dataset contains URLs:\", train_has_url)\n",
    "print(\"Test dataset contains URLs:\", test_has_url)\n",
    "print(\"Validation dataset contains URLs:\", val_has_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset contains special characters: True\n",
      "Test dataset contains special characters: True\n",
      "Validation dataset contains special characters: True\n"
     ]
    }
   ],
   "source": [
    "def has_special_characters(text):\n",
    "    pattern = re.compile(r'[^a-zA-Z0-9\\s]')\n",
    "    return bool(pattern.search(text))\n",
    "\n",
    "def check_for_special_characters(dataset):\n",
    "    for review, _ in dataset:\n",
    "        if has_special_characters(review):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "train_has_special_chars = check_for_special_characters(train_data)\n",
    "test_has_special_chars = check_for_special_characters(test_data)\n",
    "val_has_special_chars = check_for_special_characters(val_data)\n",
    "print(\"Train dataset contains special characters:\", train_has_special_chars)\n",
    "print(\"Test dataset contains special characters:\", test_has_special_chars)\n",
    "print(\"Validation dataset contains special characters:\", val_has_special_chars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mrbinit/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/mrbinit/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "# Download stopwords if not already downloaded\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Train Data: [('movie get respect sure lot memorable quote list gem imagine movie joe piscopo actually funny maureen stapleton scene stealer moroni character absolute scream watch alan skipper hale jr police sgt', 1), ('bizarre horror movie fill famous face steal cristina rain later tvs flamingo road pretty somewhat unstable model gummy smile slate pay attempt suicide guard gateway hell scene rain model well capture mood music perfect deborah raffin charming cristinas pal raine move creepy brooklyn height brownstone inhabit blind priest top floor thing really start cook neighbor include fantastically wicked burgess meredith kinky couple sylvia miles beverly dangelo diabolical lot eli wallach great fun wily police detective movie nearly crosspollination rosemarys baby exorcistbut combination base bestseller jeffrey konvitz sentinel entertainingly spooky full shock bring well director michael winner mount thoughtfully downbeat end skill 12', 1), ('solid unremarkable film matthau einstein wonderful favorite part thing would make go way see wonderful scene physicist play badmitton love sweater conversation wait robbin retrieve birdie', 1), ('strange feeling sit alone theater occupy parent rollick kid feel like instead movie ticket give nambla membershipbase upon thomas rockwell respected book eat fry worm start like children story move new town new kid fifth grader billy forrester popular start anew make friend never easy especially prospect poindexter adam erica 4 12 foot giantfurther complicate thing joe bully freckle face sleeveless shirt daunt antagonize kid death ring crackerjack ring rumor kill you re punch immediately death ring unleash poison kill eight gradejoe axis evil welcome billy smuggle handful slimy worms thermos discover billy play cool swearing eat worms time throw joe face ewww win billy reluctantly bet eat 10 worm fry boil marinated hot sauce squashed spread peanut butter sandwich meal dub exotic name like radioactive slime delight kid finally live dream microwave live organismif you ve ever meet you ll know uncontrollably hearty laugh feel like creep erupting toddler whine dilly dick hurt fry worm wonderfully disgusting like grated farrelly brother film vomitous delightfulwriterdirector bob dolman also savvy storyteller raise stake worm must consumed 7 pm addition billy hold dark secret ultrasensitive stomachdolman also keen sense perspective accuracy draw children insecurity tendency exaggerate mundane dilemmasif hyperbolize movie way kid quandary see essentially war freedomfighter freedomhater use pubescent boy pawn proxy war learn valuable lesson unity international leader learn thing two global peacekeeping fry wormsat end film comfort two chaperone mother behind look befuddlement agree great movie great will not register lawful database', 1), ('probably already know 5 additional episode never air view abccom I ve watch lot television year possibly favorite show ever crime beautifully write act show cancel actor play laura whit carlos mae damian anya omg steven caseman incredible natural role even kid great wonderful show sad go course wonder reason cancel way ill let believe ms moynahans pregnancy anything perfect time slot market I ve watch episode abccom hope come dvd day thank read', 1)]\n",
      "Cleaned Test Data: [('base actual story john boorman show struggle american doctor whose husband son murder continually plague loss holiday burma sister seem like good idea get away passport steal rangoon could leave country sister force stay back could get i d paper american embassy fill day could fly take trip countryside tour guide try find something stone statue nothing stir stone suddenly hell break loose catch political revolt look like escape safely board train see tour guide get beat shot split second decide jump move train try rescue think continually life danger woman demonstrate spontaneous selfless charity risk life save another patricia arquette beautiful look beautiful heart unforgettable story teach suffer one promise life always keep', 1), ('gem film four production anticipate quality indeed deliver shoot great style remind errol morris film well arrange simply grip long yet horrify point excruciating know something bad happen one guess lack participation person interview compel see bit like car accident slow motion story span conceivable aspect unlike documentary try refrain show grimmer side story also deal guilt people leave behind wonder do not stop time take hour get melancholy grip see verywell make documentary', 1), ('really like show drama romance comedy roll one 28 married mother identify loreleis rorys experience show watching mostly repeat family channel lately uptodate go think female would like show male know man would enjoy really like hour long half hour th hour seem fly watch give chance never see show think lorelei luke favorite character show though mainly way one another could see something take long see guess say happy viewing', 1), ('good 3d experience disney themepark certainly well original 1960 acidtrip film place league well honey shrink audience far fun barely squeak muppetvision 3d movie disneymgm even beat original 3d movie experience captain eo film relive disney great musical hit aladdin little mermaid other bring smile face throughout entire show totally kidfriendly movie unlike honey effect spectacular muppetvision', 1), ('korean movie I ve see three really stuck first excellent horror tale two sister second third fourth park chan wook movie namely oldboy sympathy lady vengeance thirst park kinda remind quentin tarantino irreverence towards convention movie shock gratuitous sense like show we do not expect see typically situation go radically societys moral like incest libidinous bloodsucke yet devout priest he s also quite artisticallyinclined regard cinematography movie among gorgeous I ve seenthirst say priest repress conscienceless woman fall horror drama even comedy park disarm audience many inappropriate yet humorous situation might well work yet since two movie I ve see lack humor element would ve make palatable repeat viewing', 1)]\n",
      "Cleaned Validation Data: [('base actual story john boorman show struggle american doctor whose husband son murder continually plague loss holiday burma sister seem like good idea get away passport steal rangoon could leave country sister force stay back could get i d paper american embassy fill day could fly take trip countryside tour guide try find something stone statue nothing stir stone suddenly hell break loose catch political revolt look like escape safely board train see tour guide get beat shot split second decide jump move train try rescue think continually life danger woman demonstrate spontaneous selfless charity risk life save another patricia arquette beautiful look beautiful heart unforgettable story teach suffer one promise life always keep', 1), ('gem film four production anticipate quality indeed deliver shoot great style remind errol morris film well arrange simply grip long yet horrify point excruciating know something bad happen one guess lack participation person interview compel see bit like car accident slow motion story span conceivable aspect unlike documentary try refrain show grimmer side story also deal guilt people leave behind wonder do not stop time take hour get melancholy grip see verywell make documentary', 1), ('really like show drama romance comedy roll one 28 married mother identify loreleis rorys experience show watching mostly repeat family channel lately uptodate go think female would like show male know man would enjoy really like hour long half hour th hour seem fly watch give chance never see show think lorelei luke favorite character show though mainly way one another could see something take long see guess say happy viewing', 1), ('good 3d experience disney themepark certainly well original 1960 acidtrip film place league well honey shrink audience far fun barely squeak muppetvision 3d movie disneymgm even beat original 3d movie experience captain eo film relive disney great musical hit aladdin little mermaid other bring smile face throughout entire show totally kidfriendly movie unlike honey effect spectacular muppetvision', 1), ('korean movie I ve see three really stuck first excellent horror tale two sister second third fourth park chan wook movie namely oldboy sympathy lady vengeance thirst park kinda remind quentin tarantino irreverence towards convention movie shock gratuitous sense like show we do not expect see typically situation go radically societys moral like incest libidinous bloodsucke yet devout priest he s also quite artisticallyinclined regard cinematography movie among gorgeous I ve seenthirst say priest repress conscienceless woman fall horror drama even comedy park disarm audience many inappropriate yet humorous situation might well work yet since two movie I ve see lack humor element would ve make palatable repeat viewing', 1)]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "# Load the English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "#identifies stop words and removes\n",
    "def remove_Stop_words(text):\n",
    "    words = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "def data_cleaning(text):\n",
    "    #convert text to lower case\n",
    "    text = text.lower()\n",
    "    #remove HTML tags\n",
    "    clean_text = re.sub(r'<.*?>', '', text)\n",
    "    #remove URLs\n",
    "    clean_text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', clean_text)\n",
    "    #remove special characters\n",
    "    clean_text = re.sub(r'[^a-zA-Z0-9\\s]', '', clean_text)\n",
    "    #handles stop words\n",
    "    clean_text = remove_Stop_words(clean_text)\n",
    "    return clean_text\n",
    "\n",
    "# Function to extend words using spaCy\n",
    "def extend_words_with_spacy(text):\n",
    "    doc = nlp(text)\n",
    "    extended_text = ' '.join([token.lemma_ for token in doc])\n",
    "    return extended_text\n",
    "\n",
    "#apply data cleaning and word extension to train data\n",
    "cleaned_train_data = [(extend_words_with_spacy(data_cleaning(review)), label) for review, label in train_data]\n",
    "\n",
    "#apply data cleaning and word extension to test data\n",
    "cleaned_test_data = [(extend_words_with_spacy(data_cleaning(review)), label) for review, label in test_data]\n",
    "\n",
    "#apply data cleaning and word extension to validation data\n",
    "cleaned_val_data = [(extend_words_with_spacy(data_cleaning(review)), label) for review, label in val_data]\n",
    "\n",
    "\n",
    "print(\"Cleaned Train Data:\", cleaned_train_data[:5])  \n",
    "print(\"Cleaned Test Data:\", cleaned_test_data[:5])   \n",
    "print(\"Cleaned Validation Data:\", cleaned_val_data[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
